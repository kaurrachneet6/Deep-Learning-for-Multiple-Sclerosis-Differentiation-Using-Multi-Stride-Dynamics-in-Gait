{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAAIMS: Predicting Multiple Sclerosis from Dynamics of Gait Variability Using an Instrumented Treadmill - A Machine Learning-Based Approach\n",
    "## Regression coefficients on controls for Trial W only - Computing the gait features for 30 controls on Trial W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Dropbox\\\\GAIT\\\\control_data\\\\Treadmill_Data_Controls\\\\Treadmill_Data_Controls\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Get all the file names in the dictionary\n",
    "control_ids = [102, 104, 105, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120,\n",
    "              122, 123, 124, 125, 126, 128, 129, 132, 133, 134, 136, 137, 138, 139, 140, 141] #30 controld - trial W data \n",
    "print (len(control_ids))\n",
    "raw_controls = [path + 'FitNIRS_'+str(i)+'_WA_NA_RAWDATA.csv' for i in control_ids] #Rawdata \n",
    "gait_controls = [path + 'FitNIRS_'+str(i)+'_WA_NA_GAITCYCLES.csv' for i in control_ids] #GaitCycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every GaitCycle file, a sequence of walk will always start with a heel strike on the right foot.\n",
    "# Thus the order of the Gait event points would be HSR, TOL, MidSSR, HSL, TOR and MidSSL.\n",
    "gait_type = np.array(['HSR', 'TOL', 'MidSSR', 'HSL', 'TOR', 'MidSSL'])\n",
    "\n",
    "#Delta_time\n",
    "delta_time = 0.002 #Since the data is collected is 500Hz frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to drop missing values and invalid data \n",
    "def drop_unnamed(dataframe):\n",
    "    return(dataframe.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1))\n",
    "\n",
    "#Eliminate missing values\n",
    "def drop_na(dataframe):\n",
    "    return(pd.DataFrame.dropna(dataframe))\n",
    "\n",
    "#Eliminate invalid data \n",
    "def get_valid(dataframe):\n",
    "    return(dataframe.loc[dataframe.Valid == True, :])\n",
    "\n",
    "# Valid strides in the gait_cycles.csv file \n",
    "def get_cycle(dataframe):\n",
    "    stride_start = min(dataframe.loc[dataframe.EventType == 'HSR'].index)\n",
    "    stride_end = max(dataframe.loc[dataframe.EventType == 'MidSSL'].index)   \n",
    "    return dataframe.loc[stride_start:stride_end]\n",
    "\n",
    "# Restore the indexing for the cropped dataframe \n",
    "def change_index(dataframe):\n",
    "    dataframe.index = range(len(dataframe))\n",
    "    return dataframe\n",
    "\n",
    "# get all the valid index in order: HSR-TOL-MidSSR-HSL-TOR-MidSSL\n",
    "def set_complete(data_frame):\n",
    "    # input is the Dataframe includes ONLY valid points \n",
    "    # get all the index of HSR since it starts with heal strike left\n",
    "    # if the length of last gait cycle contain HSR does not equals to 6, then ignore it\n",
    "    \n",
    "    HSR = data_frame.loc[data_frame.EventType == 'HSR'].index\n",
    "    last_idx = HSR[-1]\n",
    "    last_all_idx = data_frame.index[-1]\n",
    "    # if the last gait cycles contains HSR is not a valid gait cycle, then we should consider the last second HSR instead.\n",
    "    if((last_all_idx-last_idx) < 5):\n",
    "        HSR = HSR[0:-1] \n",
    "    else:\n",
    "        HSR = HSR\n",
    "    \n",
    "    # get all the valid index in order: HSR-TOL-MidSSR-HSL-TOR-MidSSL\n",
    "    valid = []\n",
    "    for idx_HSR in HSR:\n",
    "        if (((idx_HSR + 1) in data_frame.index) & ((idx_HSR + 2) in data_frame.index) &\n",
    "            ((idx_HSR + 3) in data_frame.index) & ((idx_HSR + 4) in data_frame.index) & \n",
    "            ((idx_HSR + 5) in data_frame.index)):\n",
    "            # the valid index exist in the dataframe.\n",
    "            if((data_frame.loc[idx_HSR + 1].EventType == 'TOL') & (data_frame.loc[idx_HSR + 2].EventType == 'MidSSR') & \n",
    "               (data_frame.loc[idx_HSR + 3].EventType == 'HSL') & (data_frame.loc[idx_HSR + 4].EventType == 'TOR') & \n",
    "               (data_frame.loc[idx_HSR + 5].EventType == 'MidSSL')):\n",
    "                valid.extend(range(idx_HSR, idx_HSR+6))\n",
    "    #returns the list of valid indices which form complete strides \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the files to delete missing and invalid data \n",
    "#For each person (control and MS) in Trial 1\n",
    "def cleaning(pid):\n",
    "    gait = pd.read_csv(gait_controls[pid], header = 1)\n",
    "    raw = pd.read_csv(raw_controls[pid], header = 1) \n",
    "    print ('Time recorded for PID ', pid, ' is ', raw.dropna().Time.iloc[-1])\n",
    "    gait = drop_na(gait)\n",
    "    gait  = get_valid(gait)\n",
    "\n",
    "    #Reducing to complete strides data \n",
    "    gait = get_cycle(gait)\n",
    "    indices_complete = set_complete(gait)\n",
    "    gait = gait.loc[indices_complete]\n",
    "\n",
    "    #Resetting the index \n",
    "    gait = change_index(gait)\n",
    "    return indices_complete, gait, raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our gait cycle would be HSR, TOL, MidSSR, HSL, TOR and MidSSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supporting Times\n",
    "#Double support: HSR-TOL\n",
    "#Single support (Right): TOL-MidSSR-HSL\n",
    "#Double Support: HSL-TOR\n",
    "#Signle support (Left): TOR - MidSSL-HSR (of the next stride)\n",
    "# Note, for counting supporting time of a foot for current stride, we need the HSR for the next stride\n",
    "def get_cycle_double_single(Dataframe):\n",
    "    stride_start = min(Dataframe.loc[Dataframe.EventType == 'HSR'].index)\n",
    "    stride_end = max(Dataframe.loc[Dataframe.EventType == 'HSR'].index)   \n",
    "    return Dataframe.loc[stride_start:stride_end]\n",
    "\n",
    "# delete the 'mid' points for calculating supporting time for convenience\n",
    "def delete_mid(Dataframe):\n",
    "    midl = Dataframe.loc[Dataframe.EventType == 'MidSSL'].index\n",
    "    midr = Dataframe.loc[Dataframe.EventType == 'MidSSR'].index\n",
    "    new_index = pd.Int64Index(np.arange(len(Dataframe))).difference(list(midl) + list(midr))\n",
    "    return(Dataframe.loc[pd.Int64Index(list(new_index))])\n",
    "\n",
    "#This function computes the 4 features for supporting times ,namely, double support (on right and left heels) and single support \n",
    "#(on left and right foot) \n",
    "def support(gait):\n",
    "    ####################\n",
    "    #insert the support#\n",
    "    ####################\n",
    "    double_single = get_cycle_double_single(gait) \n",
    "    #Reducing the dataframe from first HSR to last HSR for calculating supporting times\n",
    "    \n",
    "    # change the index again for counting strides\n",
    "    double_single = change_index(double_single)\n",
    "    \n",
    "    # MidSSR and MidSSL is useless for calculating the support time\n",
    "    double_single = delete_mid(double_single)\n",
    "    # get the time\n",
    "    time = list(double_single['Time'])\n",
    "    time_d_s = list(np.array(time[1:]) - np.array(time[0:-1])) \n",
    "    #Since now the events are HSR-TOL-HSL-TOR, we can simply take time[1:]-time[:-1]\n",
    "    \n",
    "    Double_LeftWhole_RightHeal = time_d_s[0::4] # support by whole left foot and right heal #HSR-TOL\n",
    "    Single_Right = time_d_s[1::4] # support bi single right feet #TOL-HSL\n",
    "    Double_RightWhole_LeftHeal = time_d_s[2::4] #HSL-TOR\n",
    "    Single_left = time_d_s[3::4] #TOR-HSR (of the next stride)\n",
    "    return Double_LeftWhole_RightHeal, Single_Right, Double_RightWhole_LeftHeal, Single_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treadmill self-controlled speed and Ground reaction forces at gait events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returning the treadmill speed or ground reaction forces at 6 gait events \n",
    "def tspeeds_forces(gait, raw, stride_count, feature = 'Speed'):\n",
    "    #Exact times of HSR\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "    #Exact times of TOR \n",
    "    TOR_times = gait['Time'][gait.EventType == 'TOR']\n",
    "    #Exact times of HSL\n",
    "    HSL_times = gait['Time'][gait.EventType == 'HSL']\n",
    "    #Exact times of TOL \n",
    "    TOL_times = gait['Time'][gait.EventType == 'TOL']\n",
    "    #Exact times of MidSSR \n",
    "    MidSSR_times = gait['Time'][gait.EventType == 'MidSSR']\n",
    "    #Exact times of MidSSL\n",
    "    MidSSL_times = gait['Time'][gait.EventType == 'MidSSL']\n",
    "\n",
    "    #For six events of interest, calculate the closest times from RAWDATA.csv file \n",
    "    #and keep the treadmill speed (tspeed) at that point if feature == 'Speed' or \n",
    "    #ground reaction force if feature == 'TreadMill_FZ'\n",
    "    HSR_raw = [raw[feature][raw['Time']>HSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOR_raw = [raw[feature][raw['Time']>TOR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    HSL_raw = [raw[feature][raw['Time']>HSL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOL_raw = [raw[feature][raw['Time']>TOL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    MidSSR_raw = [raw[feature][raw['Time']>MidSSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    MidSSL_raw = [raw[feature][raw['Time']>MidSSL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "\n",
    "    return HSR_raw, MidSSR_raw, TOR_raw, HSL_raw, TOL_raw, MidSSL_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride, swing and stance times for each stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function computing the stride, swing and stance times for each stride \n",
    "def times(gait):\n",
    "    #Exact times of HSR\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "    #Exact times of TOR \n",
    "    TOR_times = gait['Time'][gait.EventType == 'TOR']\n",
    "    #Exact times of HSL\n",
    "    HSL_times = gait['Time'][gait.EventType == 'HSL']\n",
    "    #Exact times of TOL \n",
    "    TOL_times = gait['Time'][gait.EventType == 'TOL']\n",
    "    #Exact times of MidSSR \n",
    "    MidSSR_times = gait['Time'][gait.EventType == 'MidSSR']\n",
    "    #Exact times of MidSSL\n",
    "    MidSSL_times = gait['Time'][gait.EventType == 'MidSSL']\n",
    "\n",
    "    #Stride Time = Next HSR Time - Current HSR Time\n",
    "    stride_times = HSR_times[1:].values - HSR_times[:-1].values\n",
    "\n",
    "    #Swing time = Next HSR time - Current TOR time\n",
    "    swing_times = HSR_times[1:].values - TOR_times[:-1].values\n",
    "\n",
    "    #Stance time = Current TOR time - Current HSR time \n",
    "    stance_times = TOR_times.values - HSR_times.values\n",
    "\n",
    "    return stride_times, swing_times, stance_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returning the difference between consequetive Y-coordinates \n",
    "def stride_len(y1, y2):\n",
    "    return y2-y1\n",
    "\n",
    "def length(gait, raw, indices_complete, stride_count):\n",
    "    #Function returning the stride length \n",
    "    #Exact times of HSR\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "\n",
    "    #For HSR, calculate the closest times from RAWDATA.csv file \n",
    "    HSR_times_raw = [raw['Time'][raw['Time']>HSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "\n",
    "    #Y for HSR\n",
    "    HSR_Y = gait['Y'][gait.EventType == 'HSR']\n",
    "    rely_progR = []\n",
    "\n",
    "    for idx in range(0, stride_count): #Use for all strides for each person, each trial\n",
    "        try:\n",
    "            #For Right Foot\n",
    "            #Relative y indices for HSR(i-1) to HSR(i) \n",
    "            rely_prog_idxR = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<HSR_times_raw[idx+1]) #Progression vector \n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSR(i-1) to HSR(i)\n",
    "            rely_progR.append(np.trapz(raw['Speed'][rely_prog_idxR])*0.002) \n",
    "        except:\n",
    "            pass\n",
    "    #Right Foot \n",
    "    #HSR_Y after adding the relative y correspoding to previous HSR\n",
    "    rel_HSR_Y = HSR_Y[1:].values+np.array(rely_progR) \n",
    "\n",
    "    #Stride length HSR-NextHSR \n",
    "    length = np.array(list(map(stride_len, HSR_Y[:-1].values, rel_HSR_Y)))\n",
    "\n",
    "    #Right Foot\n",
    "    #Convert in-consequetive gait cycles' stride length to NaN \n",
    "    stride_idx = np.array(indices_complete[::6][1:]) - np.array(indices_complete[::6][:-1])\n",
    "    #If this difference is not 6, that means the valid strides is not in consequent order, hence, we cannot compute lengths \n",
    "    length[np.where(stride_idx!=6)[0]] = np.nan\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stride Width = abs((x2-x1)*(y1-y0) - (x1-x0)*(y2-y1)) / np.sqrt(np.square(x2-x1) + np.square(y2-y1))\n",
    "#where (x0, y0) is the point from HS of opposite feet (i.e. coordinates of HSL)\n",
    "#and (x1,y1), (x2,y2) are coordinates that make the line joining HS(i-1) and HS(i) of same feet\n",
    "def stride_wid(x0, y0, x1, y1, x2, y2):\n",
    "    return np.abs((x2-x1)*(y1-y0) - (x1-x0)*(y2-y1)) / np.sqrt((x2-x1)**2 + (y2-y1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returning the stride width\n",
    "def calc_width(gait, raw, indices_complete, stride_count):\n",
    "    #Exact times of HSR\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "    #Exact times of HSL\n",
    "    HSL_times = gait['Time'][gait.EventType == 'HSL']\n",
    "\n",
    "    #For HSR, calculate the closest times from RAWDATA.csv file \n",
    "    HSR_times_raw = [raw['Time'][raw['Time']>HSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    #For HSL, calculate the closest times from RAWDATA.csv file \n",
    "    HSL_times_raw = [raw['Time'][raw['Time']>HSL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "\n",
    "    #Y for HSR\n",
    "    HSR_Y = gait['Y'][gait.EventType == 'HSR']\n",
    "    #Y for HSL\n",
    "    HSL_Y = gait['Y'][gait.EventType == 'HSL']\n",
    "\n",
    "    #X for HSR\n",
    "    HSR_X = gait['X'][gait.EventType == 'HSR']\n",
    "    #X for HSL\n",
    "    HSL_X = gait['X'][gait.EventType == 'HSL']\n",
    "\n",
    "    rely_progR = []\n",
    "    rely_progL = []\n",
    "\n",
    "    for idx in range(0, stride_count): #Use for all strides for each person, each trial\n",
    "        try:\n",
    "            #For Right Foot\n",
    "            #Relative y indices for HSR(i-1) to HSR(i) \n",
    "            rely_prog_idxR = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<HSR_times_raw[idx+1]) #Progression vector \n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSR(i-1) to HSR(i)\n",
    "            rely_progR.append(np.trapz(raw['Speed'][rely_prog_idxR])*0.002) \n",
    "\n",
    "            #Relative y indices for HSR(i-1) to HSL(i-1) \n",
    "            rely_prog_idxL = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<HSL_times_raw[idx]) #Progression vector \n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSR(i-1) to HSL(i-1)\n",
    "            rely_progL.append(np.trapz(raw['Speed'][rely_prog_idxL])*0.002)         \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    #Right Foot \n",
    "    #HSR_Y after adding the relative y correspoding to previous HSR\n",
    "    rel_HSR_Y = HSR_Y[1:].values+np.array(rely_progR) \n",
    "    #Left Foot \n",
    "    #HSL_Y after adding the relative y correspoding to same stride's HSR\n",
    "    rel_HSL_Y = HSL_Y[:-1].values+np.array(rely_progL) \n",
    "\n",
    "    #Stride width HSR-HSL-NextHSR \n",
    "    width = np.array(list(map(stride_wid, HSL_X[:-1].values, rel_HSL_Y, HSR_X[:-1].values, HSR_Y[:-1].values, \n",
    "                                     HSR_X[1:].values, rel_HSR_Y)))\n",
    "\n",
    "    #Right Foot\n",
    "    #Convert in-consequetive gait cycles' stride width to NaN \n",
    "    stride_idx = np.array(indices_complete[::6][1:]) - np.array(indices_complete[::6][:-1])\n",
    "    #If this difference is not 6, that means the valid strides is not in consequent order, hence, we cannot compute lengths \n",
    "    width[np.where(stride_idx!=6)[0]] = np.nan\n",
    "    return width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing all the gait-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending the 24 features \n",
    "def gait_features(pid):\n",
    "    df = pd.DataFrame()\n",
    "    indices_complete, gait, raw = cleaning(pid)\n",
    "    stride_count = int(gait.shape[0]/6) #6 events in each stride\n",
    "    \n",
    "    #Inserting the supporting times \n",
    "    DS_R, SS_R, DS_L, SS_L = support(gait)\n",
    "    #Total length must match the stride count \n",
    "    #Append NaN at the end for all the supporting times since for SS_L, we need the next stride available, \n",
    "    #hence SS_L does not exist for the last stride\n",
    "    df['DS_R'], df['SS_R'], df['DS_L'], df['SS_L'] = np.append(DS_R, np.nan), np.append(SS_R, np.nan), np.append(DS_L, np.nan), np.append(SS_L, np.nan)\n",
    "    \n",
    "    #Inserting the treadmill speeds \n",
    "    df['tspeed_HSR'], df['tspeed_MidSSR'], df['tspeed_TOR'], df['tspeed_HSL'], df['tspeed_TOL'], df['tspeed_MidSSL'] = tspeeds_forces(gait, raw, stride_count, 'Speed')\n",
    "    \n",
    "    #Inserting the ground reaction forces \n",
    "    df['force_HSR'], df['force_MidSSR'], df['force_TOR'], df['force_HSL'], df['force_TOL'], df['force_MidSSL'] = tspeeds_forces(gait, raw, stride_count, 'TreadMill_FZ')\n",
    "    \n",
    "    #Inserting the stride, stance and swing times \n",
    "    stride_time, swing_time, stance_time= times(gait)\n",
    "    #Append NaN at the end for all the stride and swing time since we need next stride for computation of these at current stride\n",
    "    df['stride_time'], df['swing_time'] = np.append(stride_time, np.nan), np.append(swing_time, np.nan)\n",
    "    df['stance_time'] = stance_time\n",
    "    \n",
    "    #Inserting the stride length \n",
    "    stride_length = length(gait, raw, indices_complete, stride_count)\n",
    "    #For length, append NaN at the end\n",
    "    df['stride_length'] = np.append(stride_length, np.nan)\n",
    "    \n",
    "    #Inserting the stride width\n",
    "    stride_width = calc_width(gait, raw, indices_complete, stride_count)\n",
    "    #For stride width, append NaN at the end \n",
    "    df['stride_width'] = np.append(stride_width, np.nan)\n",
    "    \n",
    "    #Inserting the stride speed\n",
    "    df['stride_speed'] = df['stride_length']/df['stride_time']\n",
    "    \n",
    "    #Inserting the cadence (steps per minute i.e. 60*2/stride_time since 1 stride has 2 steps \n",
    "    #and stride time is in seconds so multiple by 60 to compute steps in a minute)\n",
    "    df['cadence'] = 60*2/df['stride_time'] \n",
    "    \n",
    "    #Inserting the walk ratio = sride_length/(strides per minute) where stride_per_min = cadence/2 (Unit: m/strides/min)\n",
    "    df['walk_ratio'] = 2*df['stride_length']/df['cadence']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time recorded for PID  0  is  177.737999995797\n",
      "Time recorded for PID  1  is  151.326000030829\n",
      "Time recorded for PID  2  is  173.248000025191\n",
      "Time recorded for PID  3  is  154.892000031556\n",
      "Time recorded for PID  4  is  168.88599999700898\n",
      "Time recorded for PID  5  is  151.83399999641\n",
      "Time recorded for PID  6  is  151.979999996406\n",
      "Time recorded for PID  7  is  169.98599999598\n",
      "Time recorded for PID  8  is  155.390000017652\n",
      "Time recorded for PID  9  is  153.972000031368\n",
      "Time recorded for PID  10  is  180.95199999572102\n",
      "Time recorded for PID  11  is  141.199999996661\n",
      "Time recorded for PID  12  is  168.19199999602301\n",
      "Time recorded for PID  13  is  152.349999996397\n",
      "Time recorded for PID  14  is  171.123999995953\n",
      "Time recorded for PID  15  is  200.94799999524798\n",
      "Time recorded for PID  16  is  178.44999999578\n",
      "Time recorded for PID  17  is  171.06999999595502\n",
      "Time recorded for PID  18  is  216.238000001033\n",
      "Time recorded for PID  19  is  197.54599999532903\n",
      "Time recorded for PID  20  is  166.065999996073\n",
      "Time recorded for PID  21  is  203.380000041434\n",
      "Time recorded for PID  22  is  159.44599999623\n",
      "Time recorded for PID  23  is  156.57600003189899\n",
      "Time recorded for PID  24  is  191.535999995471\n",
      "Time recorded for PID  25  is  155.60799999632\n",
      "Time recorded for PID  26  is  166.029999996074\n",
      "Time recorded for PID  27  is  161.097999996191\n",
      "Time recorded for PID  28  is  150.579999996439\n",
      "Time recorded for PID  29  is  163.543999996133\n"
     ]
    }
   ],
   "source": [
    "#Dataframe with Patient ID, Trial ID, (Right FPA, Left FPA for each stride)\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for index in range(0, 30): #30 controls for trial W\n",
    "    pid = control_ids[index]\n",
    "    df = gait_features(index)\n",
    "\n",
    "    temp_df = pd.DataFrame(data = np.array([[pid]*len(df)]).T)\n",
    "    temp_df.columns = ['PID']\n",
    "    temp_df = pd.concat([temp_df, df], axis = 1)\n",
    "    final_df = final_df.append(temp_df, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>DS_R</th>\n",
       "      <th>SS_R</th>\n",
       "      <th>DS_L</th>\n",
       "      <th>SS_L</th>\n",
       "      <th>tspeed_HSR</th>\n",
       "      <th>tspeed_MidSSR</th>\n",
       "      <th>tspeed_TOR</th>\n",
       "      <th>tspeed_HSL</th>\n",
       "      <th>tspeed_TOL</th>\n",
       "      <th>...</th>\n",
       "      <th>force_TOL</th>\n",
       "      <th>force_MidSSL</th>\n",
       "      <th>stride_time</th>\n",
       "      <th>swing_time</th>\n",
       "      <th>stance_time</th>\n",
       "      <th>stride_length</th>\n",
       "      <th>stride_width</th>\n",
       "      <th>stride_speed</th>\n",
       "      <th>cadence</th>\n",
       "      <th>walk_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.853843</td>\n",
       "      <td>0.832884</td>\n",
       "      <td>0.794530</td>\n",
       "      <td>0.811716</td>\n",
       "      <td>0.849651</td>\n",
       "      <td>...</td>\n",
       "      <td>865.859765</td>\n",
       "      <td>805.434696</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.946</td>\n",
       "      <td>1.404388</td>\n",
       "      <td>0.075299</td>\n",
       "      <td>0.968544</td>\n",
       "      <td>82.758621</td>\n",
       "      <td>0.033939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.865579</td>\n",
       "      <td>0.963664</td>\n",
       "      <td>1.046869</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>0.926358</td>\n",
       "      <td>...</td>\n",
       "      <td>891.600148</td>\n",
       "      <td>829.797523</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.808027</td>\n",
       "      <td>0.150372</td>\n",
       "      <td>0.741309</td>\n",
       "      <td>110.091743</td>\n",
       "      <td>0.014679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.418</td>\n",
       "      <td>1.046450</td>\n",
       "      <td>1.025072</td>\n",
       "      <td>1.014803</td>\n",
       "      <td>0.992796</td>\n",
       "      <td>1.024234</td>\n",
       "      <td>...</td>\n",
       "      <td>949.259385</td>\n",
       "      <td>805.615205</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.832</td>\n",
       "      <td>1.132094</td>\n",
       "      <td>0.079525</td>\n",
       "      <td>0.905675</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.023585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.356</td>\n",
       "      <td>1.019204</td>\n",
       "      <td>0.997617</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>1.002437</td>\n",
       "      <td>1.033665</td>\n",
       "      <td>...</td>\n",
       "      <td>914.069152</td>\n",
       "      <td>825.344213</td>\n",
       "      <td>1.236</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.017947</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.823582</td>\n",
       "      <td>97.087379</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.949622</td>\n",
       "      <td>0.901628</td>\n",
       "      <td>0.883394</td>\n",
       "      <td>0.910011</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>...</td>\n",
       "      <td>908.027960</td>\n",
       "      <td>825.620958</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.876773</td>\n",
       "      <td>0.173470</td>\n",
       "      <td>0.671342</td>\n",
       "      <td>91.883614</td>\n",
       "      <td>0.019084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID   DS_R   SS_R   DS_L   SS_L  tspeed_HSR  tspeed_MidSSR  tspeed_TOR  \\\n",
       "0  102  0.214  0.496  0.236  0.504    0.853843       0.832884    0.794530   \n",
       "1  102  0.270  0.334  0.190  0.296    0.865579       0.963664    1.046869   \n",
       "2  102  0.180  0.438  0.214  0.418    1.046450       1.025072    1.014803   \n",
       "3  102  0.248  0.370  0.262  0.356    1.019204       0.997617    0.976449   \n",
       "4  102  0.218  0.430  0.222  0.436    0.949622       0.901628    0.883394   \n",
       "\n",
       "   tspeed_HSL  tspeed_TOL  ...   force_TOL  force_MidSSL  stride_time  \\\n",
       "0    0.811716    0.849651  ...  865.859765    805.434696        1.450   \n",
       "1    0.991748    0.926358  ...  891.600148    829.797523        1.090   \n",
       "2    0.992796    1.024234  ...  949.259385    805.615205        1.250   \n",
       "3    1.002437    1.033665  ...  914.069152    825.344213        1.236   \n",
       "4    0.910011    0.935580  ...  908.027960    825.620958        1.306   \n",
       "\n",
       "   swing_time  stance_time  stride_length  stride_width  stride_speed  \\\n",
       "0       0.504        0.946       1.404388      0.075299      0.968544   \n",
       "1       0.296        0.794       0.808027      0.150372      0.741309   \n",
       "2       0.418        0.832       1.132094      0.079525      0.905675   \n",
       "3       0.356        0.880       1.017947      0.158556      0.823582   \n",
       "4       0.436        0.870       0.876773      0.173470      0.671342   \n",
       "\n",
       "      cadence  walk_ratio  \n",
       "0   82.758621    0.033939  \n",
       "1  110.091743    0.014679  \n",
       "2   96.000000    0.023585  \n",
       "3   97.087379    0.020970  \n",
       "4   91.883614    0.019084  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterfly diagram based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference: https://github.com/sukhbinder/intersection/blob/master/intersection.py\n",
    "Sukhbinder\n",
    "5 April 2017\n",
    "\"\"\"\n",
    "\n",
    "def _rect_inter_inner(x1,x2):\n",
    "    n1=x1.shape[0]-1\n",
    "    n2=x2.shape[0]-1\n",
    "    X1=np.c_[x1[:-1],x1[1:]]\n",
    "    X2=np.c_[x2[:-1],x2[1:]]\n",
    "    S1=np.tile(X1.min(axis=1),(n2,1)).T\n",
    "    S2=np.tile(X2.max(axis=1),(n1,1))\n",
    "    S3=np.tile(X1.max(axis=1),(n2,1)).T\n",
    "    S4=np.tile(X2.min(axis=1),(n1,1))\n",
    "    return S1,S2,S3,S4\n",
    "\n",
    "def _rectangle_intersection_(x1,y1,x2,y2):\n",
    "    S1,S2,S3,S4=_rect_inter_inner(x1,x2)\n",
    "    S5,S6,S7,S8=_rect_inter_inner(y1,y2)\n",
    "\n",
    "    C1=np.less_equal(S1,S2)\n",
    "    C2=np.greater_equal(S3,S4)\n",
    "    C3=np.less_equal(S5,S6)\n",
    "    C4=np.greater_equal(S7,S8)\n",
    "\n",
    "    ii,jj=np.nonzero(C1 & C2 & C3 & C4)\n",
    "    return ii,jj\n",
    "\n",
    "def intersection(x1,y1,x2,y2):\n",
    "    '''\n",
    "    INTERSECTIONS Intersections of curves.\n",
    "       Computes the (x,y) locations where two curves intersect.  The curves\n",
    "       can be broken with NaNs or have vertical segments.\n",
    "    usage:\n",
    "    x,y=intersection(x1,y1,x2,y2)\n",
    "    '''\n",
    "    ii,jj=_rectangle_intersection_(x1,y1,x2,y2)\n",
    "    n=len(ii)\n",
    "\n",
    "    dxy1=np.diff(np.c_[x1,y1],axis=0)\n",
    "    dxy2=np.diff(np.c_[x2,y2],axis=0)\n",
    "\n",
    "    T=np.zeros((4,n))\n",
    "    AA=np.zeros((4,4,n))\n",
    "    AA[0:2,2,:]=-1\n",
    "    AA[2:4,3,:]=-1\n",
    "    AA[0::2,0,:]=dxy1[ii,:].T\n",
    "    AA[1::2,1,:]=dxy2[jj,:].T\n",
    "\n",
    "    BB=np.zeros((4,n))\n",
    "    BB[0,:]=-x1[ii].ravel()\n",
    "    BB[1,:]=-x2[jj].ravel()\n",
    "    BB[2,:]=-y1[ii].ravel()\n",
    "    BB[3,:]=-y2[jj].ravel()\n",
    "\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            T[:,i]=np.linalg.solve(AA[:,:,i],BB[:,i])\n",
    "        except:\n",
    "            T[:,i]=np.NaN\n",
    "\n",
    "\n",
    "    in_range= (T[0,:] >=0) & (T[1,:] >=0) & (T[0,:] <=1) & (T[1,:] <=1)\n",
    "\n",
    "    xy0=T[2:,in_range]\n",
    "    xy0=xy0.T\n",
    "    return xy0[:,0],xy0[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating butterfly diagrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For generating the butterfly diagrams for Controls, PwMS Trial W and Trial WT\n",
    "def butterfly_plots(pid):\n",
    "    indices_complete, gait, raw = cleaning(pid)\n",
    "\n",
    "    #For the four events of interest for butterfly diagram, computing the times from GAITCYCLES.csv file\n",
    "    # HSR-TOL-MidSSR-HSL-TOR-MidSSL\n",
    "    #Line 1 is COPs from HSR-TOL, Line 2 is COPs from HSL-TOR\n",
    "    #gait = gait[(gait['Time']>30) & (gait['Time']<60)] \n",
    "    #Taking only 30-60 seconds of the trial for cleaner results for mean trajectory \n",
    "    stride_count = int(gait.shape[0]/6) #6 events in each stride\n",
    "\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "    HSL_times = gait['Time'][gait.EventType == 'HSL']\n",
    "    TOR_times = gait['Time'][gait.EventType == 'TOR']\n",
    "    TOL_times = gait['Time'][gait.EventType == 'TOL']\n",
    "    \n",
    "    #Taking only 30-60 seconds of the trial for cleaner results for mean trajectory     \n",
    "    stride_start_index_clean = np.where(HSR_times>30)[0][0]\n",
    "    stride_stop_index_clean = np.where(HSR_times<60)[0][-1]\n",
    "    \n",
    "    #For four events of interest, calculate the closest times from RAWDATA.csv file \n",
    "    #Closest to TOL times in raw data \n",
    "    HSR_times_raw = [raw['Time'][raw['Time']>HSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    HSL_times_raw = [raw['Time'][raw['Time']>HSL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOR_times_raw = [raw['Time'][raw['Time']>TOR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOL_times_raw = [raw['Time'][raw['Time']>TOL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    \n",
    "    #For each stride in current person-current trial \n",
    "    #HSR-TOL-MidSSR-HSL-TOR-MidSSL\n",
    "    #plt.figure(figsize = (6,9))\n",
    "    line1s_x, line1s_y = [], []\n",
    "    line2s_x, line2s_y = [], []\n",
    "    line3s_x, line3s_y = [], []\n",
    "    line4s_x, line4s_y= [], []\n",
    "    IPs_x, IPs_y = [], [] #Intersection points (x, y) for each stride \n",
    "\n",
    "    #for idx in range(stride_start_index_clean, stride_stop_index_clean): #Stride index for each person-each trial #use for mean\n",
    "    for idx in range(0, stride_count): #Use for all strides \n",
    "        try:\n",
    "            stride_idx = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<HSR_times_raw[idx+1])\n",
    "            COP1_idx = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<TOL_times_raw[idx])\n",
    "            line1 = raw[['COPX', 'COPY']][COP1_idx] - raw[['COPX', 'COPY']][stride_idx].mean()\n",
    "            line1s_x.append(list(line1['COPX'].values))\n",
    "            line1s_y.append(list(line1['COPY'].values))\n",
    "\n",
    "            COP2_idx = (raw['Time']>=HSL_times_raw[idx]) & (raw['Time']<TOR_times_raw[idx])\n",
    "            line2 = raw[['COPX', 'COPY']][COP2_idx] - raw[['COPX', 'COPY']][stride_idx].mean()\n",
    "            line2s_x.append(list(line2['COPX'].values))\n",
    "            line2s_y.append(list(line2['COPY'].values))\n",
    "\n",
    "            COP3_idx = (raw['Time']>=TOL_times_raw[idx]) & (raw['Time']<HSL_times_raw[idx])\n",
    "            line3 = raw[['COPX', 'COPY']][COP3_idx] - raw[['COPX', 'COPY']][stride_idx].mean()\n",
    "            line3s_x.append(list(line3['COPX'].values))\n",
    "            line3s_y.append(list(line3['COPY'].values))\n",
    "\n",
    "            COP4_idx = (raw['Time']>=TOR_times_raw[idx]) & (raw['Time']<HSR_times_raw[idx+1])\n",
    "            line4 = raw[['COPX', 'COPY']][COP4_idx] - raw[['COPX', 'COPY']][stride_idx].mean()\n",
    "            line4s_x.append(list(line4['COPX'].values))\n",
    "            line4s_y.append(list(line4['COPY'].values))\n",
    "\n",
    "        \n",
    "            IP_x, IP_y = intersection(line1['COPX'].values, line1['COPY'].values, line2['COPX'].values, line2['COPY'].values)\n",
    "            IPs_x.append(IP_x)\n",
    "            IPs_y.append(IP_y)\n",
    "            \n",
    "            '''\n",
    "            #Plotting for each stride \n",
    "            plt.plot(line1.iloc[:,0].values, line1.iloc[:, 1].values, 'c-', alpha = 0.4)\n",
    "            plt.plot(line2.iloc[:,0].values, line2.iloc[:, 1].values, 'c-', alpha = 0.4)\n",
    "            plt.plot(line3.iloc[:,0].values, line3.iloc[:, 1].values, 'c-', alpha = 0.4)\n",
    "            plt.plot(line4.iloc[:,0].values, line4.iloc[:, 1].values, 'c-', alpha = 0.4)\n",
    "            #plt.plot(IP_x, IP_y, 'yo')\n",
    "            '''\n",
    "        except: #For the last stride when HSR of next stride is unavailable \n",
    "            continue \n",
    "    '''\n",
    "    #For plotting the clean mean trajectory, we use normalization w.r.t time \n",
    "    line1_mean = np.array([pd.DataFrame(line1s_x).iloc[:, :301].interpolate(method='linear', limit_direction='forward', axis=1).mean(), \n",
    "                           pd.DataFrame(line1s_y).iloc[:, :301].interpolate(method='linear', limit_direction='forward', axis=1).mean()])\n",
    "    line2_mean = np.array([pd.DataFrame(line2s_x).iloc[:, :271].interpolate(method='linear', limit_direction='forward', axis=1).mean(), \n",
    "                           pd.DataFrame(line2s_y).iloc[:, :271].interpolate(method='linear', limit_direction='forward', axis=1).mean()])\n",
    "    line3_mean = np.array([pd.DataFrame(line3s_x).iloc[:, :231].interpolate(method='linear', limit_direction='forward', axis=1).mean(), \n",
    "                           pd.DataFrame(line3s_y).iloc[:, :231].interpolate(method='linear', limit_direction='forward', axis=1).mean()])\n",
    "    line4_mean = np.array([pd.DataFrame(line4s_x).iloc[:, :211].interpolate(method='linear', limit_direction='forward', axis=1).mean(), \n",
    "                       pd.DataFrame(line4s_y).iloc[:, :211].interpolate(method='linear', limit_direction='forward', axis=1).mean()])\n",
    "    plt.plot(line1_mean[0], line1_mean[1], 'k-', linewidth=4, label = None)\n",
    "    plt.plot(line2_mean[0], line2_mean[1], 'k-', linewidth=4, label = None)\n",
    "    plt.plot(line3_mean[0], line3_mean[1], 'k-', linewidth=4, label = None)\n",
    "    plt.plot(line4_mean[0], line4_mean[1], 'k-', linewidth=4, label = 'average trajectory')    \n",
    "    plt.plot(np.mean(pd.DataFrame(IPs_x))[0], np.mean(pd.DataFrame(IPs_y))[0], 'gd')\n",
    "    plt.xlim((-0.25,0.25))\n",
    "    plt.ylim((-0.5, 0.5))\n",
    "    #plt.xlabel('Position of center of pressure in x-direction')\n",
    "    #plt.ylabel('Position of center of pressure in y-direction')\n",
    "    #plt.title('Butterfly diagram: PwMS ID ' + str(pid+1) + ', Trial Walking & Talking (WT)')\n",
    "    #plt.savefig(path + '..\\\\butterfly\\\\' + 'pwms'+str(pid+1)+'_trial'+str(trial_id)+'.jpg')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    return IPs_x, IPs_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the intersection points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time recorded for PID  0  is  177.737999995797\n",
      "Time recorded for PID  1  is  151.326000030829\n",
      "Time recorded for PID  2  is  173.248000025191\n",
      "Time recorded for PID  3  is  154.892000031556\n",
      "Time recorded for PID  4  is  168.88599999700898\n",
      "Time recorded for PID  5  is  151.83399999641\n",
      "Time recorded for PID  6  is  151.979999996406\n",
      "Time recorded for PID  7  is  169.98599999598\n",
      "Time recorded for PID  8  is  155.390000017652\n",
      "Time recorded for PID  9  is  153.972000031368\n",
      "Time recorded for PID  10  is  180.95199999572102\n",
      "Time recorded for PID  11  is  141.199999996661\n",
      "Time recorded for PID  12  is  168.19199999602301\n",
      "Time recorded for PID  13  is  152.349999996397\n",
      "Time recorded for PID  14  is  171.123999995953\n",
      "Time recorded for PID  15  is  200.94799999524798\n",
      "Time recorded for PID  16  is  178.44999999578\n",
      "Time recorded for PID  17  is  171.06999999595502\n",
      "Time recorded for PID  18  is  216.238000001033\n",
      "Time recorded for PID  19  is  197.54599999532903\n",
      "Time recorded for PID  20  is  166.065999996073\n",
      "Time recorded for PID  21  is  203.380000041434\n",
      "Time recorded for PID  22  is  159.44599999623\n",
      "Time recorded for PID  23  is  156.57600003189899\n",
      "Time recorded for PID  24  is  191.535999995471\n",
      "Time recorded for PID  25  is  155.60799999632\n",
      "Time recorded for PID  26  is  166.029999996074\n",
      "Time recorded for PID  27  is  161.097999996191\n",
      "Time recorded for PID  28  is  150.579999996439\n",
      "Time recorded for PID  29  is  163.543999996133\n"
     ]
    }
   ],
   "source": [
    "#One with PatientID, TrialID, Mean(x), Mean(y), SD(x), SD(y)\n",
    "df1 = pd.DataFrame()\n",
    "#Another with Patient ID, Trial ID, x, y, (x-mean(x))^2, (y-mean(y))^2\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for index in range(0, 30): #30 controls in trial W\n",
    "    pid = control_ids[index]\n",
    "    IPs_x, IPs_y = butterfly_plots(index)\n",
    "\n",
    "    IPs_x = pd.DataFrame(IPs_x)[0]\n",
    "    IPs_y = pd.DataFrame(IPs_y)[0]\n",
    "    #Append NaN at the end to compensate for last stride not computed \n",
    "    IPs_x  = IPs_x.append(pd.Series([np.nan]), ignore_index = True)\n",
    "    IPs_y = IPs_y.append(pd.Series([np.nan]), ignore_index = True)\n",
    "    IPs_x_abs = IPs_x.abs()\n",
    "    IPs_y_abs = IPs_y.abs()\n",
    "    mean_x = IPs_x.mean()\n",
    "    mean_y = IPs_y.mean()\n",
    "    mean_x_abs = IPs_x_abs.mean()\n",
    "    mean_y_abs = IPs_y_abs.mean()\n",
    "    sd_x = IPs_x.std()\n",
    "    sd_y = IPs_y.std()\n",
    "    df1 = df1.append([[pid, mean_x, mean_y, mean_x_abs, mean_y_abs, sd_x, sd_y]], ignore_index=True)\n",
    "    squared_diff_x = (IPs_x- mean_x)**2\n",
    "    squared_diff_y = (IPs_y- mean_y)**2\n",
    "    temp_df = pd.DataFrame([[pid]*len(IPs_x),list(IPs_x.values), list(IPs_y.values), \n",
    "                            list(IPs_x_abs.values), list(IPs_y_abs.values), list(squared_diff_x.values), \n",
    "                            list(squared_diff_y.values)]).T\n",
    "    df2 = df2.append(temp_df, ignore_index= True)\n",
    "\n",
    "df1.columns = ['PID', 'ButterflyMean_x', 'ButterflyMean_y', 'ButterflyMean_x_abs', 'ButterflyMean_y_abs', \n",
    "               'ButterflySD_x', 'ButterflySD_y']\n",
    "df2.columns = ['PID', 'Butterfly_x', 'Butterfly_y', 'Butterfly_x_abs', 'Butterfly_y_abs', \n",
    "               'ButterflySQ_x', 'ButterflySQ_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving 2 csvs\n",
    "#One with PatientID, TrialID, Mean(x), Mean(y), SD(x), SD(y)\n",
    "df1.to_csv(path+'..\\\\..\\\\extracted_features\\\\ButterflyMeanSD_30controlsTrialW.csv')\n",
    "#Another with Patient ID, Trial ID, x, y, (x-mean(x))^2, (y-mean(y))^2\n",
    "df2.to_csv(path+'..\\\\..\\\\extracted_features\\\\ButterflyFeatures_30controlsTrialW.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foot progression angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foot progression angle - right foot\n",
    "def FPA_right(x1, x2, y1, y2):\n",
    "    return np.arctan2((y2 - y1), (x2 - x1)) / math.pi *  180\n",
    "\n",
    "#Left foot progression angle \n",
    "def FPA_left(x1, x2, y1, y2):\n",
    "    return np.arctan2((y2 - y1), (x2 - x1)) / math.pi * 180 * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foot Progression Calculator function given Patient ID\n",
    "def FPA_calculator(pid):\n",
    "    indices_complete, gait, raw = cleaning(pid)\n",
    "\n",
    "    stride_count = int(gait.shape[0]/6) #6 events in each stride\n",
    "\n",
    "    #Exact times of HSR\n",
    "    HSR_times = gait['Time'][gait.EventType == 'HSR']\n",
    "    #Exact times of TOR \n",
    "    TOR_times = gait['Time'][gait.EventType == 'TOR']\n",
    "    #Exact times of HSL\n",
    "    HSL_times = gait['Time'][gait.EventType == 'HSL']\n",
    "    #Exact times of TOL \n",
    "    TOL_times = gait['Time'][gait.EventType == 'TOL']\n",
    "\n",
    "    #X for HSR\n",
    "    HSR_X = gait['X'][gait.EventType == 'HSR']\n",
    "    #X for TOR \n",
    "    TOR_X = gait['X'][gait.EventType == 'TOR']\n",
    "    #X for HSL\n",
    "    HSL_X = gait['X'][gait.EventType == 'HSL']\n",
    "    #X for TOL\n",
    "    TOL_X = gait['X'][gait.EventType == 'TOL']\n",
    "\n",
    "    #Y for HSR\n",
    "    HSR_Y = gait['Y'][gait.EventType == 'HSR']\n",
    "    #Y for TOR \n",
    "    TOR_Y = gait['Y'][gait.EventType == 'TOR']\n",
    "    #Y for HSL\n",
    "    HSL_Y = gait['Y'][gait.EventType == 'HSL']\n",
    "    #Y for TOL\n",
    "    TOL_Y = gait['Y'][gait.EventType == 'TOL']\n",
    "\n",
    "    #For four events of interest, calculate the closest times from RAWDATA.csv file \n",
    "    HSR_times_raw = [raw['Time'][raw['Time']>HSR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOR_times_raw = [raw['Time'][raw['Time']>TOR_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    HSL_times_raw = [raw['Time'][raw['Time']>HSL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "    TOL_times_raw = [raw['Time'][raw['Time']>TOL_times.iloc[i]].iloc[0] for i in range(stride_count)]\n",
    "\n",
    "    rely_progR = []\n",
    "    rely_footR = []\n",
    "    rely_progL = []\n",
    "    rely_footL = []\n",
    "\n",
    "    for idx in range(0, stride_count): #Use for all strides for each person, each trial\n",
    "        try:\n",
    "            #For Right Foot\n",
    "            #Relative y indices for HSR(i-1) to HSR(i) \n",
    "            rely_prog_idxR = (raw['Time']>=HSR_times_raw[idx]) & (raw['Time']<HSR_times_raw[idx+1]) #Progression vector \n",
    "\n",
    "            #Relative y indices for HSR(i) to TOR(i) \n",
    "            rely_foot_idxR = (raw['Time']>=HSR_times_raw[idx+1]) & (raw['Time']<TOR_times_raw[idx+1]) #Foot direction vector\n",
    "\n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSR(i-1) to HSR(i)\n",
    "            rely_progR.append(np.trapz(raw['Speed'][rely_prog_idxR])*0.002) \n",
    "\n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSR(i) to TOR(i)\n",
    "            rely_footR.append(np.trapz(raw['Speed'][rely_foot_idxR])*0.002) \n",
    "\n",
    "            #For Left Foot \n",
    "            #Relative y indices for HSL(i-1) to HSL(i) \n",
    "            rely_prog_idxL = (raw['Time']>=HSL_times_raw[idx]) & (raw['Time']<HSL_times_raw[idx+1]) #Progression vector \n",
    "\n",
    "            #Relative y indices for HSL(i) to TOL(i+1) \n",
    "            rely_foot_idxL = (raw['Time']>=HSL_times_raw[idx+1]) & (raw['Time']<TOL_times_raw[idx+2]) #Foot direction vector\n",
    "\n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSL(i-1) to HSL(i)\n",
    "            rely_progL.append(np.trapz(raw['Speed'][rely_prog_idxL])*0.002) \n",
    "\n",
    "            #Relative_y or Belt Speed = Speed*dt = Area under the speed curve *dt for HSL(i) to TOL(i+1)\n",
    "            rely_footL.append(np.trapz(raw['Speed'][rely_foot_idxL])*0.002) \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #Right Foot \n",
    "    #HSR_Y after adding the relative y correspoding to previous HSR\n",
    "    rel_HSR_Y = HSR_Y[1:].values+np.array(rely_progR) \n",
    "    #TOR_Y after adding the relative y corresponding to same foot HSR starting from foot 2\n",
    "    rel_TOR_Y = TOR_Y[1:].values+np.array(rely_footR) \n",
    "\n",
    "    #Left Foot\n",
    "    #HSL_Y of foot 2(stride 2) after adding the relative y correspoding to previous HSL (first and last one cannot be used)\n",
    "    #First one cannot be used since we need first 2 to compute Heel-Heel angle\n",
    "    #Last one cannot be used since we need TOL of next stride (which doesn't exist) to compute HeelLeft-Toe Left angle \n",
    "    rel_HSL_Y = HSL_Y[1:-1].values+np.array(rely_progL) \n",
    "    #TOL_Y of foot 2 (stride 3) after adding the relative y corresponding to same foot HSL starting from foot 2 \n",
    "    #(first 2 will not be used)\n",
    "    rel_TOL_Y = TOL_Y[2:].values+np.array(rely_footL) \n",
    "\n",
    "    #Right FPA\n",
    "    #HSR-NextHSR angle with horizontal axis \n",
    "    HH_R = list(map(FPA_right, HSR_X[:-1].values, HSR_X[1:].values, HSR_Y[:-1].values, rel_HSR_Y))\n",
    "    #HSR-TOR angle with horizontal axis starting from second HSR \n",
    "    HT_R = list(map(FPA_right, HSR_X[1:].values, TOR_X[1:].values, HSR_Y[1:].values, rel_TOR_Y))\n",
    "    #Right Foot Progression angle = angle of HH with horixontal axis - angle of HT with horizontal axis\n",
    "    rightFPA = np.array(HH_R)-np.array(HT_R)\n",
    "\n",
    "    #Left FPA\n",
    "    #HSL-NextHSL angle with horizontal axis \n",
    "    HH_L = list(map(FPA_left, HSL_X[:-2].values, HSL_X[1:-1].values, HSL_Y[:-2].values, rel_HSL_Y))\n",
    "    #HSL-TOL angle with horizontal axis starting from second HSL\n",
    "    HT_L = list(map(FPA_left, HSL_X[1:-1].values, TOL_X[2:].values, HSL_Y[1:-1].values, rel_TOL_Y))\n",
    "    #Right Foot Progression angle = angle of HH with horixontal axis - angle of HT with horizontal axis\n",
    "    leftFPA = np.array(HH_L)-np.array(HT_L)\n",
    "    \n",
    "    #Right Foot\n",
    "    #Convert in-consequetive gait cycles' angles to NaN \n",
    "    stride_idx = np.array(indices_complete[::6][1:]) - np.array(indices_complete[::6][:-1])\n",
    "    #If this difference is not 6, that means the valid strides is not in consequent order, hence, we cannot compute angles \n",
    "    rightFPA[np.where(stride_idx!=6)[0]] = np.nan\n",
    "    #Total length must match the stride count \n",
    "    #For RFPA, append NaN at the beginning\n",
    "    rightFPA = np.insert(rightFPA, 0, np.nan)\n",
    "\n",
    "    #Left Foot\n",
    "    #If this difference is not 6, that means the valid strides is not in consequent order, hence, we cannot compute angles \n",
    "    for x in np.where(stride_idx!=6)[0]:\n",
    "        if ((x-1)>=0): #For 0th index, only 0 should be Nan, else, x-1 and x should be Nan\n",
    "            leftFPA[x-1] = np.nan\n",
    "        try: \n",
    "            #For last index, LeftFPA has length no. of strides-2, so, for the last stride to be non-consequetive, \n",
    "            #there will be no current LeftFPA value to be nullified \n",
    "            leftFPA[x] = np.nan\n",
    "        except:\n",
    "            pass\n",
    "    #Total length must match the stride count \n",
    "    #For LFPA, append NaN at the beginning and at the end\n",
    "    leftFPA = np.insert(leftFPA, 0, np.nan)\n",
    "    leftFPA= np.append(leftFPA, np.nan)\n",
    "    \n",
    "    return leftFPA, rightFPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataframe and storing in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time recorded for PID  0  is  177.737999995797\n",
      "Time recorded for PID  1  is  151.326000030829\n",
      "Time recorded for PID  2  is  173.248000025191\n",
      "Time recorded for PID  3  is  154.892000031556\n",
      "Time recorded for PID  4  is  168.88599999700898\n",
      "Time recorded for PID  5  is  151.83399999641\n",
      "Time recorded for PID  6  is  151.979999996406\n",
      "Time recorded for PID  7  is  169.98599999598\n",
      "Time recorded for PID  8  is  155.390000017652\n",
      "Time recorded for PID  9  is  153.972000031368\n",
      "Time recorded for PID  10  is  180.95199999572102\n",
      "Time recorded for PID  11  is  141.199999996661\n",
      "Time recorded for PID  12  is  168.19199999602301\n",
      "Time recorded for PID  13  is  152.349999996397\n",
      "Time recorded for PID  14  is  171.123999995953\n",
      "Time recorded for PID  15  is  200.94799999524798\n",
      "Time recorded for PID  16  is  178.44999999578\n",
      "Time recorded for PID  17  is  171.06999999595502\n",
      "Time recorded for PID  18  is  216.238000001033\n",
      "Time recorded for PID  19  is  197.54599999532903\n",
      "Time recorded for PID  20  is  166.065999996073\n",
      "Time recorded for PID  21  is  203.380000041434\n",
      "Time recorded for PID  22  is  159.44599999623\n",
      "Time recorded for PID  23  is  156.57600003189899\n",
      "Time recorded for PID  24  is  191.535999995471\n",
      "Time recorded for PID  25  is  155.60799999632\n",
      "Time recorded for PID  26  is  166.029999996074\n",
      "Time recorded for PID  27  is  161.097999996191\n",
      "Time recorded for PID  28  is  150.579999996439\n",
      "Time recorded for PID  29  is  163.543999996133\n"
     ]
    }
   ],
   "source": [
    "#Dataframe with Patient ID, Trial ID, (Right FPA, Left FPA for each stride)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for index in range(0, 30): #30 controls in Trial W\n",
    "    pid = control_ids[index]\n",
    "    leftFPA, rightFPA = FPA_calculator(index)\n",
    "\n",
    "    temp_df = pd.DataFrame(data = np.array([[pid]*len(leftFPA), leftFPA, rightFPA]).T)\n",
    "    df = df.append(temp_df, ignore_index= True)\n",
    "df.columns = ['PID', 'LeftFPA', 'RightFPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv((path+'..\\\\..\\\\extracted_features\\\\FPAs_30controlsTrialW.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all features together, including butterfly features and angles to create a final raw dataframe \n",
    "#Also inserting the labels \n",
    "FPAs = pd.read_csv(path+'..\\\\..\\\\extracted_features\\\\FPAs_30controlsTrialW.csv')\n",
    "butterfly = pd.read_csv(path+'..\\\\..\\\\extracted_features\\\\ButterflyFeatures_30controlsTrialW.csv')\n",
    "whole_df = pd.concat([FPAs[['LeftFPA', 'RightFPA']], butterfly[['Butterfly_x_abs', 'Butterfly_y_abs', \n",
    "                                                                'ButterflySQ_x', 'ButterflySQ_y']], final_df], axis = 1)  \n",
    "#Saving to .csv \n",
    "whole_df.to_csv(path + '..\\\\..\\\\extracted_features\\\\gait_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4011, 31)\n"
     ]
    }
   ],
   "source": [
    "print (whole_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
